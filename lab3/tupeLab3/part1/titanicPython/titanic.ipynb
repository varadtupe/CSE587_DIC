{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pyspark\n",
    "import os\n",
    "import csv\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark import SparkContext, SparkConf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = pyspark.SparkConf()\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainTitanic = sc.textFile(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainHeader = trainTitanic.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '0',\n",
       " '3',\n",
       " 'Braund, Mr. Owen Harris',\n",
       " 'male',\n",
       " '22',\n",
       " '1',\n",
       " '0',\n",
       " 'A/5 21171',\n",
       " '7.25',\n",
       " '',\n",
       " 'S']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainTitanic = trainTitanic.filter(lambda line: line != trainHeader).mapPartitions(lambda x: csv.reader(x))\n",
    "trainTitanic.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "def sexTransformMapper(elem):\n",
    "    '''Function which transform \"male\" into 1 and else things into 0\n",
    "    - elem : string\n",
    "    - return : vector\n",
    "    '''\n",
    "     \n",
    "    if elem == 'male' :\n",
    "        return [0]\n",
    "    else :\n",
    "        return [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '3', 0, '22', '1', '0', 'A/5 21171', '7.25', ''],\n",
       " ['1', '1', 1, '38', '1', '0', 'PC 17599', '71.2833', 'C85'],\n",
       " ['1', '3', 1, '26', '0', '0', 'STON/O2. 3101282', '7.925', ''],\n",
       " ['1', '1', 1, '35', '1', '0', '113803', '53.1', 'C123'],\n",
       " ['0', '3', 0, '35', '0', '0', '373450', '8.05', ''],\n",
       " ['0', '1', 0, '54', '0', '0', '17463', '51.8625', 'E46'],\n",
       " ['0', '3', 0, '2', '3', '1', '349909', '21.075', ''],\n",
       " ['1', '3', 1, '27', '0', '2', '347742', '11.1333', ''],\n",
       " ['1', '2', 1, '14', '1', '0', '237736', '30.0708', ''],\n",
       " ['1', '3', 1, '4', '1', '1', 'PP 9549', '16.7', 'G6']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Transformations and filter lines with empty strings\n",
    "trainTitanic=trainTitanic.map(lambda line: line[1:3]+sexTransformMapper(line[4])+line[5:11])\n",
    "trainTitanic=trainTitanic.filter(lambda line: line[3] != '' ).filter(lambda line: line[4] != '' )\n",
    "trainTitanic.take(10)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledPoint(0.0, [3.0,0.0,22.0,1.0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating \"labeled point\" rdds specific to MLlib \"(label (v1, v2...vp])\"\n",
    "trainTitanicLP=trainTitanic.map(lambda line: LabeledPoint(line[0],[line[1:5]]))\n",
    "trainTitanicLP.first()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting dataset into train and test set\n",
    "(trainData, testData) = trainTitanicLP.randomSplit([0.7, 0.3])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random forest : same parameters as sklearn (?)\n",
    "from pyspark.mllib.tree import RandomForest\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Titanic using mllib module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF takes 3 s\n",
      "Area under PR = 0.6303521511910549\n",
      "Area under ROC = 0.8107253086419752\n"
     ]
    }
   ],
   "source": [
    "time_start=time.time()\n",
    "model_rf = RandomForest.trainClassifier(trainData, numClasses = 2,\n",
    "        categoricalFeaturesInfo = {}, numTrees = 100,\n",
    "        featureSubsetStrategy='auto', impurity='gini', maxDepth=12,\n",
    "        maxBins=32, seed=None)\n",
    " \n",
    "model_rf.numTrees()\n",
    "model_rf.totalNumNodes()\n",
    "time_end=time.time()\n",
    "time_rf=(time_end - time_start)\n",
    "print(\"RF takes %d s\" %(time_rf))\n",
    " \n",
    "# Predictions on test set\n",
    "predictions = model_rf.predict(testData.map(lambda x: x.features))\n",
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    " \n",
    "# first metrics\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "metrics = BinaryClassificationMetrics(labelsAndPredictions)\n",
    " \n",
    "# Area under precision-recall curve\n",
    "print(\"Area under PR = %s\" % metrics.areaUnderPR)\n",
    " \n",
    "# Area under ROC curve\n",
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|  22|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|  38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|  26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|  35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|  35|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|  54|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|   2|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|  27|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|  14|    1|    0|          237736|30.0708| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Titanic using sql dataframe and ml module\n",
    "# Import packages\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, OneHotEncoder, VectorAssembler, IndexToString\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import *\n",
    " \n",
    "# Creatingt Spark SQL environment\n",
    "from pyspark.sql import SparkSession, HiveContext\n",
    "SparkContext.setSystemProperty(\"hive.metastore.uris\", \"thrift://nn1:9083\")\n",
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()\n",
    " \n",
    "# spark is an existing SparkSession\n",
    "train = spark.read.csv(\"train.csv\", header = True)\n",
    "# Displays the content of the DataFrame to stdout\n",
    "train.show(10)\n",
    " \n",
    "# String to float on some columns of the dataset : creates a new dataset\n",
    "train = train.select(col(\"Survived\"),col(\"Sex\"),col(\"Embarked\"),col(\"Pclass\").cast(\"float\"),col(\"Age\").cast(\"float\"),col(\"SibSp\").cast(\"float\"),col(\"Fare\").cast(\"float\"))\n",
    " \n",
    "# dropping null values\n",
    "train = train.dropna()\n",
    " \n",
    "# Spliting in train and test set. Beware : It sorts the dataset\n",
    "(traindf, testdf) = train.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|prediction|         probability|\n",
      "+----------+--------------------+\n",
      "|       0.0|[0.88456654531564...|\n",
      "|       1.0|[0.00593513083883...|\n",
      "|       0.0|[0.54744931634004...|\n",
      "|       1.0|[0.05213437577430...|\n",
      "|       0.0|[0.84976862878837...|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Without Pipeline\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "train = StringIndexer(inputCol=\"Sex\", outputCol=\"indexedSex\").fit(train).transform(train)\n",
    "train = StringIndexer(inputCol=\"Embarked\", outputCol=\"indexedEmbarked\").fit(train).transform(train)\n",
    " \n",
    "train = StringIndexer(inputCol=\"Survived\", outputCol=\"indexedSurvived\").fit(train).transform(train)\n",
    " \n",
    "# One Hot Encoder on indexed features\n",
    "train = OneHotEncoder(inputCol=\"indexedSex\", outputCol=\"sexVec\").transform(train)\n",
    "train = OneHotEncoder(inputCol=\"indexedEmbarked\", outputCol=\"embarkedVec\").transform(train)\n",
    " \n",
    "# Feature assembler as a vector\n",
    "train = VectorAssembler(inputCols=[\"Pclass\",\"sexVec\",\"embarkedVec\", \"Age\",\"SibSp\",\"Fare\"],outputCol=\"features\").transform(train)\n",
    " \n",
    "rf = RandomForestClassifier(labelCol=\"indexedSurvived\", featuresCol=\"features\")\n",
    " \n",
    "model = rf.fit(train)\n",
    " \n",
    "predictions = model.transform(train)\n",
    " \n",
    "# Select example rows to display.\n",
    "predictions.select(col(\"prediction\"),col(\"probability\"),).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|[3.0,0.0,18.0,0.0...|\n",
      "|       1.0|       0|[1.0,0.0,25.0,1.0...|\n",
      "|       1.0|       0|[2.0,0.0,26.0,1.0...|\n",
      "|       0.0|       0|[3.0,0.0,6.0,4.0,...|\n",
      "|       0.0|       0|[3.0,0.0,9.0,3.0,...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.196347\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_4e1890c754739e363151) with 20 trees\n",
      "Accuracy = 0.803653\n",
      "f1 = 0.795099\n",
      "weightedPrecision = 0.823745\n",
      "weightedRecall = 0.803653\n"
     ]
    }
   ],
   "source": [
    "# With Pipeline\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "genderIndexer = StringIndexer(inputCol=\"Sex\", outputCol=\"indexedSex\")\n",
    "embarkIndexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"indexedEmbarked\")\n",
    " \n",
    "surviveIndexer = StringIndexer(inputCol=\"Survived\", outputCol=\"indexedSurvived\")\n",
    " \n",
    "# One Hot Encoder on indexed features\n",
    "genderEncoder = OneHotEncoder(inputCol=\"indexedSex\", outputCol=\"sexVec\")\n",
    "embarkEncoder = OneHotEncoder(inputCol=\"indexedEmbarked\", outputCol=\"embarkedVec\")\n",
    " \n",
    "# Create the vector structured data (label,features(vector))\n",
    "assembler = VectorAssembler(inputCols=[\"Pclass\",\"sexVec\",\"Age\",\"SibSp\",\"Fare\",\"embarkedVec\"],outputCol=\"features\")\n",
    " \n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedSurvived\", featuresCol=\"features\")\n",
    " \n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[surviveIndexer, genderIndexer, embarkIndexer, genderEncoder,embarkEncoder, assembler, rf]) # genderIndexer,embarkIndexer,genderEncoder,embarkEncoder,\n",
    " \n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(traindf)\n",
    " \n",
    "# Predictions\n",
    "predictions = model.transform(testdf)\n",
    " \n",
    "# Select example rows to display.\n",
    "predictions.columns \n",
    " \n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"Survived\", \"features\").show(5)\n",
    " \n",
    "# Select (prediction, true label) and compute test error\n",
    "predictions = predictions.select(col(\"Survived\").cast(\"Float\"),col(\"prediction\"))\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    " \n",
    "rfModel = model.stages[6]\n",
    "print(rfModel)  # summary only\n",
    " \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g\" % accuracy)\n",
    " \n",
    "evaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluatorf1.evaluate(predictions)\n",
    "print(\"f1 = %g\" % f1)\n",
    " \n",
    "evaluatorwp = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "wp = evaluatorwp.evaluate(predictions)\n",
    "print(\"weightedPrecision = %g\" % wp)\n",
    " \n",
    "evaluatorwr = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "wr = evaluatorwr.evaluate(predictions)\n",
    "print(\"weightedRecall = %g\" % wr)\n",
    " \n",
    "# close sparkcontext\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
