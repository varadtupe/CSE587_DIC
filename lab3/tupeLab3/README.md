
lab3 Data Intensive Computing
###################################################################
team members: 

Varad Tupe 50249001
Krithika Krishnan 50169047

###################################################################
Part 1: 

files found in "part1" folder. 
titanic data analysis done through scala and pyspark on separate files.

The scala implementation is found in "spark-kaggle-master" folder and the python implementation is found in "titanicPython" folder.

titanic dataset was analysed using pyspark in a jupyter notebook named, "titanic.ipynb"

We also used scala code to test on the titanic dataset using the submit.sh script. output of which will be available in the "classified.csv" file. 


part 2: 

Files found in "part2" folder. 

lab3.ipynb entails the code used to extract, load, build, test model, and visualize the NY Times articles from MY Times article search API. The articles were stored in two pickle files, "trainingCV.pickle" and "searchData.pickle".


###################################################################
references: 

https://creativedata.atlassian.net/wiki/spaces/SAP/pages/83237142/Pyspark+-+Tutorial+based+on+Titanic+Dataset

https://github.com/BenFradet/spark-kaggle

https://developer.nytimes.com/

https://spark.apache.org/docs/2.3.0/ml-guide.html

http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html

###################################################################
